X<-rnorm(1000,4,5)
X<-rnorm(10000,4,5)
X<-rnorm(100000,4,5)
X<-rnorm(1000000,4,5)
X<-rnorm(10000000,4,5)
X<-rnorm(100000000,4,5)
X<-rnorm(1000000000,4,5)
X<-rnorm(500000000,4,5)
X<-rnorm(600000000,4,5)
rm(list = ls())
shiny::runApp('GitHub/mi_proyecto1_est_383/Shiny/prueba1/ProyEST383')
load(url("https://pspp.benpfaff.org/pspp2text.cgi")
install.packages("xtable")
install.packages("sparklyr")
library(sparklyr)
spark_install()
spark_available_versions()
spark_installed_versions()
rm(list = ls())
library(sparklyr)
spark_installed_versions()
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.4.3")
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.4.3")
library(sparklyr)
spark_install(version = "2.3")
library(sparklyr)
spark_install(version = "2.3")
spark_installed_versions()
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.3.3")
library(sparklyr)
spark_install(version = "2.3")
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.3.3")
library(sparklyr)
spark_install()
library(sparklyr)
spark_install()
spark_install()
spark_installed_versions()
spark_install()
library(sparklyr)
spark_install()
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.3.3")
#inicio de sesion
sc<-spark_connect( master = "local", version = "2.4.3")
spark_disconnect(sc)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(dplyr)
load("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\eh18.RData")
attributes(eh18p)
atributes(eeh18p)
attributes(eh18p)$variable.labels
names(eh18p)
attributes(eh18p)$variable.labels
View(eh18p)
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR"& ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05="1.JEFE O JEFA DEL HOGAR"& ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05="1.JEFE O JEFA DEL HOGAR" & ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR" & ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR" & ocupado="Si")
library(dplyr)
attributes(eh18p)$variable.labels
names(eh18p)
eh18p$s02a_05
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05=="1.JEFE O JEFA DEL HOGAR" & ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 )#& s02a_05 =="1.JEFE O JEFA DEL HOGAR" & ocupado="Si")
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05 =="1.JEFE O JEFA DEL HOGAR") #& ocupado="Si")
eh18p$ocupado
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05 =="1.JEFE O JEFA DEL HOGAR" & ocupado=="Si")
names(eh18p)
bd<-eh18p %>% filter(s02a_03>=18 & s02a_05 =="1.JEFE O JEFA DEL HOGAR" & ocupado=="Si") %>% select(s02a_02,s02a_03,aestudio,ylab,tothrs,ynolab,factor,estrato,upm,area,permanente,cob_op)
View(eh18p)
View(eh18p)
library(normtest)
install.packages("normtest")
install.packages("MASS")
install.packages("car")
install.packages("lmtest")
library(mfx)
install.packages("mfx")
install.packages("DescTools")
install.packages("memisc")
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(dplyr)
load("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVID19MEXICO.csv",sep=",",na.strings=c(99,98))
covid<-read.csv("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVID19MEXICO.csv",sep=",",na.strings=c(99,98))
View(covid)
View(covid)
names(covid)
attributes(covid)
covid<-covid %>% filter(EDAD<=90)
#descripcion
Hmisc::describe(covid)
#descripcion
install.packages("Hmisc")
Hmisc::describe(covid)
#descripcion
#install.packages("Hmisc")
Hmisc::describe(covid)
#variable muerte (para clasificarlos)
covid$muerte<-(covid$FECHA_DEF!="9999-99-99")
covid<-covid %>% select(-FECHA_DEF)
covid<-na.omit(covid)
rm(list = ls())
library(dplyr)
covid<-read.csv("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVI::describe(covid)
#variable muerte (para clasificarlos)
covid$muerte<-(covid$FECHA_DEF!="9999-99-99")
coviD19MEXICO.csv",sep=",",na.strings=c(99,98))
covid<-read.csv("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVI::describe(covid)
#variable muerte (para clasificarlos)
covid$muerte<-(covid$FECHA_DEF!="9999-99-99")
coviD19MEXICO.csv",sep=",",na.strings=c(99,98))
attributes(covid)
covid<-read.csv("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVID19MEXICO.csv",sep=",",na.strings=c(99,98))
attributes(covid)
covid<-covid %>% filter(EDAD<=90)
#descripcion
#install.packages("Hmisc")
Hmisc::describe(covid)
#variable muerte (para clasificarlos)
covid$muerte<-(covid$FECHA_DEF!="9999-99-99")
covid<-covid %>% select(-FECHA_DEF)
covid<-na.omit(covid)
covid<-na.omit(covid)
rm(list = ls())
library(dplyr)
covid<-read.csv("C:\\Users\\Dell\\Documents\\GitHub\\EST-384\\data\\covid_mx\\200627COVID19MEXICO.csv",sep=",",na.strings=c(99,98))
attributes(covid)
covid<-covid %>% filter(EDAD<=90)
#variable muerte (para clasificarlos)
covid$muerte<-(covid$FECHA_DEF!="9999-99-99")
covid<-covid %>% select(-FECHA_DEF)
#covid<-na.omit(covid)
str(covid)
covid$SEXO<-factor(covid$SEXO,levels = 1:2,labels = c("mujer","hombre"))
str(covid)
install.packages("rpart")
library("rpart.plot")
install.packages("rpart.plot")
install.packages("caret")
prune()
?prune
library(rpart)
install.packages("e1071")
library(tm)
fb<-read.csv("bd_sc.csv")
library(tm)
library(dplyr)
setwd("C:\\Users\\Dell\\Documents\\GitHub\\clase_EST_384\\clases\\clase_06_07_20")
fb<-read.csv("bd_sc.csv")
fb<-read.csv("bd_sc.csv",encoding = "UTF-8")
#fb<-read.csv("bd_sc.csv",encoding = "Latin-1")
fb$post_text[5]
library(pdftools)
dir<-"C:\\Users\\Dell\\Documents\\GitHub\\clase_EST_384\\clases\\clase_06_07_20"
pdfdocs<-VCorpus(DirSource(dir,pattern = ".pdf"),
readerControl = list(reader =readPDF))
#install.packages("rtweet")
library(rtweet)
tw<-search_tweets("Dioxido de Cloro",n=10000,include_rts = F)
tw
View(tw)
#install.packages("wordcloud2")
library(wordcloud2)
nube<-function(aux){
docs<-Corpus(VectorSource(aux))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
return(df)
}
nube2<-function(aux){
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
return(df)
}
nube<-function(aux){
docs<-aux
docs<-Corpus(VectorSource(aux))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
return(df)
}
#csv
df<-nube(fb$post_text)
wordcloud2(data=df,color='random-dark',size = 0.4,shape = 'pentagon')
#colección de documentos
df<-nube2(pdfdocs)
nube2<-function(aux){
docs <- aux %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
return(df)
}
#colección de documentos
df<-nube2(pdfdocs)
wordcloud2(data=df,color='random-dark',size = 0.4,shape = 'pentagon')
#scrape
df<-nube(tw$text)
wordcloud2(data=df[df$freq>1,],color='random-dark',shape = 'pentagon')
library(ggplot2)
#install.packages("ggthemes")
library(ggthemes)
docs<-VCorpus(VectorSource(fb$text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
tdm<-TermDocumentMatrix(docs)
associations<-findAssocs(tdm, 'evo', 0.55)
associations<-as.data.frame(associations)
associations$terms<-row.names(associations)
associations$terms<-factor(associations$terms,
levels=associations$terms)
names(associations)[1]<-"palabra"
ggplot(associations, aes(y=terms)) +
geom_point(aes(x=palabra), data=associations,
size=5)+
theme_gdocs()+ geom_text(aes(x=palabra,
label=palabra),
colour="darkred",hjust=-.25,size=8)+
theme(text=element_text(size=20),
axis.title.y=element_blank())
View(associations)
#solo ingles
library(qdap)
library(syuzhet)
install.packages("syuzhet")
#install.packages("syuzhet")
library(syuzhet)
library(rtweet)
tw<-search_tweets("coronavirus",n=1000,include_rts = F,lang="es")
ww<-get_sentiment_dictionary("nrc",language = "spanish")
View(ww)
View(ww)
aa<-get_nrc_sentiment(tw$text,language = "spanish")
View(docs)
aa
barplot(apply(aa,2,sum),horiz = T,las=1)
attributes(ww)
get_nrc_sentiment
lexicon <- dplyr::filter_(nrc, ~lang == language)
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
get_nrc_values
nrc_data
nrc_data
nrc
nrc_data
tw$text
aa<-get_nrc_sentiment(tw$text[1],language = "spanish")
aa<-get_nrc_sentiment(tw$text[5],language = "spanish")
barplot(apply(aa,2,sum),horiz = T,las=1)
aa<-get_nrc_sentiment(tw$text[1:2],language = "spanish")
barplot(apply(aa,2,sum),horiz = T,las=1)
aa<-get_nrc_sentiment(tw$text[1:5],language = "spanish")
barplot(apply(aa,2,sum),horiz = T,las=1)
aa
apply(aa,2,sum)
barplot(apply(aa,2,sum))#,horiz = T,las=1)
barplot(apply(aa,2,sum),horiz = T,las=1)
aa<-get_nrc_sentiment(tw$text,language = "spanish")
apply(aa,2,sum)
barplot(apply(aa,2,sum),horiz = T,las=1)
barplot(apply(aa,2,sum),horiz = T,las=1)
rm(list = ls())
#install.packages("syuzhet")
library(syuzhet)
library(rtweet)
tw<-search_tweets("coronavirus",n=1000,include_rts = F,lang="es")
ww<-get_sentiment_dictionary("nrc",language = "spanish")#guardar nrc lexicon
aa<-get_nrc_sentiment(tw$text,language = "spanish")
apply(aa,2,sum)
barplot(apply(aa,2,sum),horiz = T,las=1)
